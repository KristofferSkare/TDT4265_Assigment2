{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 4 Report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an outline for your report to ease the amount of work required to create your report. Jupyter notebook supports markdown, and I recommend you to check out this [cheat sheet](https://github.com/adam-p/markdown-here/wiki/Markdown-Cheatsheet). If you are not familiar with markdown.\n",
    "\n",
    "Before delivery, **remember to convert this file to PDF**. You can do it in two ways:\n",
    "1. Print the webpage (ctrl+P or cmd+P)\n",
    "2. Export with latex. This is somewhat more difficult, but you'll get somehwat of a \"prettier\" PDF. Go to File -> Download as -> PDF via LaTeX. You might have to install nbconvert and pandoc through conda; `conda install nbconvert pandoc`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## task 1a)\n",
    "\n",
    "![](IoU_drawing.png)\n",
    "\n",
    "The drawing illustrates the intersection and union of two bounding boxes. The \"Intersection over Union\" (IoU) is the ratio of these two areas:\n",
    "\n",
    "$$\n",
    "\\text{IoU} = \\frac{\\text{Intersection}}{\\text{Union}} \n",
    "$$\n",
    "\n",
    "If we first find the intersection by comparing the two boxes x and y coordinates. The union can be found by summing up the two areas of the two bounding boxes and subtracting the intersection. \n",
    "\n",
    "The intersection in x can be found by summing up the width of the two rectangles and subtracting the largest distance between two x coordinates: \n",
    "$$\n",
    "\\text{Intersection}_x = \\Delta x_{gt} + \\Delta x_{pred} - (x_{max} - x_{min})\n",
    "$$\n",
    "\n",
    "where $x_{max}$ and $x_{min}$ are the maximum and minimum of all the x coordinates. \n",
    "\n",
    "Similarly the intersection in y can be found using the same formula with the y coordinates. \n",
    "\n",
    "Multiplying the intersection in x and y gives the intersectional area. \n",
    "\n",
    "$$\n",
    "\\text{Intersection} = (\\Delta x_{gt} + \\Delta x_{pred} - (x_{max} - x_{min}))(\\Delta y_{gt} + \\Delta y_{pred} - (y_{max} - y_{min}))\n",
    "$$\n",
    "\n",
    "If either the x or y intersection is negative then the Intersection is 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## task 1b)\n",
    "\n",
    "Precision: $\\frac {TP} {TP+FP}$\n",
    "\n",
    "Recall: $\\frac {TP} {TP+FN}$\n",
    "\n",
    "True positive (TP) is when a predicted positive is also a ground truth positive, whereas a false positive is a predicted true which did not correspond with the ground truth.\n",
    "\n",
    "## task 1c)\n",
    "\n",
    "Fill in task 1a image of hand-written notes which are easy to read, or latex equations here\n",
    "\n",
    "Smoothened:\n",
    "\n",
    "$mAP_{1,s} = 1 \\cdot 0.4 + 0.5 \\cdot 0.3 + 0.2 \\cdot 0.3 = 0.61$ \n",
    "\n",
    "$mAP_{2,s} = 1 \\cdot 0.3 + 0.8 \\cdot 0.1 + 0.6 \\cdot 0.1 + 0.5 \\cdot 0.2 + 0.2 \\cdot 0.3 = 0.6$ \n",
    "\n",
    "$mAP_s = \\frac {0.61 + 0.6}{2} = 0.606$\n",
    "\n",
    "Not smoothened:\n",
    "\n",
    "$mAP_1 = mAP_{1,s} + 0.5 \\cdot (0.3 \\cdot 0.5 + 0.3 \\cdot 0.3) = 0.73$\n",
    "\n",
    "$mAP_2 = mAP{2,s} + 0.5 \\cdot (0.1 \\cdot 0.2 + 0.1 \\cdot 0.2 +0.1 \\cdot 0.2 + 0.3 \\cdot 0.3) = 0.675$\n",
    "\n",
    "$mAP = \\frac {0.73 + 0.675} {2} = 0.7025$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2\n",
    "\n",
    "### Task 2f)\n",
    "![](./task2/precision_recall_curve.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3a)\n",
    "The filtering operation is called NMS, or Non-Maximum Suppression. It filters out the boxes that has an IoU lower than a given threshold.\n",
    "\n",
    "### Task 3b)\n",
    "False. Because the images become smaller when we go deeper down the layers, it is harder to detect small objects. The deeper layers are more useful for detecting key features in objects. \n",
    "\n",
    "### Task 3c)\n",
    "They use different bounding box aspect rations for classification. Different objects will have different ratios and therefore it is useful with different bounding box aspect ratios. \n",
    "\n",
    "### Task 3d)\n",
    "YOLO uses k-means clustering to determine the boundary boxes whereas SSD uses default boxes that are chosen manually.\n",
    "\n",
    "### Task 3e)\n",
    "$38 \\times 38$ is 1444 anchor locations on a 38 by 38 grid. Num anchors: $1444 \\cdot 6 = 8664$\n",
    "\n",
    "### Task 3f)\n",
    "$(38\\cdot 38 + 19\\cdot 19 + 10\\cdot 10 + 5 \\cdot 5 + 3\\cdot 3 + 1\\cdot 1) \\cdot 6 = 11640$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4b)\n",
    "\n",
    "![](./SSD/notebooks/total_loss_SSD.png)\n",
    "\n",
    "The final mean average precision (mAP) was 76.5\\%\n",
    "\n",
    "## Task 4c)\n",
    "In order to improve the model, we introduced batch normalization and changed the optimizer from SGD to Adam (with slightly reduced learning rate and weight decay). In addition to this, we increased the batch size to 64 and doubled the amount of nodes in the last layer. We also removed the first ReLU in the \"blocks\", because the model previously had ReLU's twice in a row where the latter one is redundant. This got the training at best to **81.5%** precision, and the final mAP was **79.3%**. \n",
    "\n",
    "This was the best attempt out of many... \n",
    "\n",
    "We tried using:\n",
    "\n",
    "- tuning of the SGD optimizer (lr, momentum, and weight decay)\n",
    "- drop-out\n",
    "  - With a low drop-out rate (0.2-0.3) it did not sufficiently improve the model, and beyond that it only made it worse.\n",
    "- average pooling\n",
    "  - Similarly as in Assignment 3, it decreased the performance of the model. \n",
    "- increasing number of output nodes in the different \"blocks\"\n",
    "  - With more output nodes it seemed like the model had a harder time training and converged around 70% mAP. However, we probably could experiment more here\n",
    "- adding a convolutional layer in all the middle of the blocks\n",
    "  - Similar to increasing the number of output nodes.. \n",
    "  \n",
    "It has been challenging and time consuming to experiment with different architechtures as it takes a long time to see how it performs. Sometimes the model had very bad performance in the beginning, but got a lot better after many steps. Other times it was very good in the beginning, however it did not improve much after. Many times during training, the mAP fluxuated between higher and lower values. This could indicate that the model was overtrained. It also really struggled with class 1 at times...\n",
    "\n",
    "\n",
    "## Task 4d)\n",
    "\n",
    "The stride corresponding to the $5 \\times 5$ feature map is $(64,64)$. \n",
    "This means that the anchor locations are placed in $(32 + 64 \\cdot i, 32 + 64 \\cdot j)$\n",
    "Pixel values of anchor locations:\n",
    "\n",
    "(32, 32), (32, 96), (32, 160), (32, 224), (32, 288), (96, 32), (96, 96), (96, 160), (96, 224), (96, 288), (160, 32), (160, 96), (160, 160), (160, 224), (160, 288), (224, 32), (224, 96), (224, 160), (224, 224), (224, 288), (288, 32), (288, 96), (288, 160), (288, 224), (288, 288)\n",
    "\n",
    "\n",
    "Size of anchor boxes: \n",
    "[162, 162], [185, 185], [114, 229], [229, 114], [93, 280], [280, 93]\n",
    " \n",
    "![](./SSD/notebooks/priors.png)\n",
    "\n",
    "## Task 4e)\n",
    "![](./SSD/demo/mnist_output/0.png)\n",
    "![](./SSD/demo/mnist_output/1.png)\n",
    "![](./SSD/demo/mnist_output/2.png)\n",
    "![](./SSD/demo/mnist_output/3.png)\n",
    "![](./SSD/demo/mnist_output/4.png)\n",
    "![](./SSD/demo/mnist_output/5.png)\n",
    "![](./SSD/demo/mnist_output/6.png)\n",
    "![](./SSD/demo/mnist_output/7.png)\n",
    "![](./SSD/demo/mnist_output/8.png)\n",
    "![](./SSD/demo/mnist_output/9.png)\n",
    "![](./SSD/demo/mnist_output/10.png)\n",
    "![](./SSD/demo/mnist_output/11.png)\n",
    "![](./SSD/demo/mnist_output/12.png)\n",
    "![](./SSD/demo/mnist_output/13.png)\n",
    "![](./SSD/demo/mnist_output/14.png)\n",
    "\n",
    "It seems the model was struggling to detect smaller numbers. It also assumes that there are 3's everywhere. Even though average precision seems to be good, it does not seems like it after looking at these results. Regarding the issue earlier with our model struggling with one specific class, it might be caused by classifying many parts of the picture as that number.\n",
    "\n",
    "## Task 4f)\n",
    "FILL IN ANSWER. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 32), (32, 96), (32, 160), (32, 224), (32, 288), (96, 32), (96, 96), (96, 160), (96, 224), (96, 288), (160, 32), (160, 96), (160, 160), (160, 224), (160, 288), (224, 32), (224, 96), (224, 160), (224, 224), (224, 288), (288, 32), (288, 96), (288, 160), (288, 224), (288, 288),\n"
     ]
    }
   ],
   "source": [
    "n = 5\n",
    "s = 64\n",
    "points = []\n",
    "\n",
    "for i in range(n):\n",
    "    for j in range(n):\n",
    "        points.append(\"({}, {}),\".format(int(s/2 + s*i), int(s/2 + s*j)))\n",
    "\n",
    "print(*points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[162, 162], [185, 185], [114, 229], [229, 114], [93, 280], [280, 93],\n"
     ]
    }
   ],
   "source": [
    "from math import sqrt\n",
    "\n",
    "size = 162\n",
    "next_size = 213\n",
    "ratios = [2,3]\n",
    "\n",
    "sizes = []\n",
    "\n",
    "sizes.append(\"[{}, {}],\".format(size, size))\n",
    "sq = int(sqrt(size*next_size))\n",
    "sizes.append(\"[{}, {}],\".format(sq,sq))\n",
    "\n",
    "for r in ratios:\n",
    "    l = int(size/sqrt(r))\n",
    "    h = int(size*sqrt(r))\n",
    "    sizes.append(\"[{}, {}],\".format(l, h))\n",
    "    sizes.append(\"[{}, {}],\".format(h, l))\n",
    "\n",
    "print(*sizes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
